source("/home/aivo/kool/R/mydistfun.R")
require(graphics)
# this is autogenerated test data
load(file="/home/aivo/kool/R/kNN_data1.RData")
# clear previous plots
graphics.off()

covariance <- function(p) {
  X = p[1,]
  Y = p[2,]
  # translate X so as to get the result to have a mean of 0
  x.no.mean = X - (sum(X) / length(X))
  y.no.mean = Y - (sum(Y) / length(Y))
  x.no.mean * y.no.mean / (length(x) -1)
}

my_kmeans <- function(x, k, threshold=0.01) {
  calc.new.means <- function(x, clusters, k) {
    means <- c()
    for(c in 1:k)
    {
      # select the points with the matching cluster index
      cluster <- which(clusters == c)
      
      # compute the mean point of all points in cluster c
      mt1 <- mean(x[cluster,1])
      mt2 <- mean(x[cluster,2])
      vMean <- c(mt1, mt2)
      means <- c(means, vMean)
    }
    means <- matrix(means, ncol=2, byrow=TRUE)
    return(means)
  }
  
  delta <- function(prev, new) {
    diff <- new - prev
    # transpose for the distance function
    max(euclidean.dist(t(diff)))
  }
  
  # Returns a vector with cluster numbers per each row in the input matrix
  calc.clusters <- function(x, means) {
    clusters = c()
    n <- nrow(x)
    for(i in 1:n)
    {
      distances = c()
      m <- nrow(means)
      # for each cluster calculate distance from cluster means
      for(j in 1:m)
      {
        dst <- euclidean.dist(x[i,] - means[j,])
        distances <- c(distances, dst)
      }
      min.distance <- min(distances)
      # find the index position in vector
      cluster <- match(min.distance, distances)
      clusters <- c(clusters, cluster)    
    }
    return (clusters)
  }
  
  # Sample k random points from input matrix as initial centroids
  initial <- x[sample(nrow(x), k), ]
  
  means <- initial
  prev.means <- initial
  # Just to make sure that the while loop runs at least once
  difference <- threshold + 1 
  prev.means <- means
  iterations <- 0
  
  while(difference > threshold) {
    clusters = calc.clusters(x, means)
    prev.means <- means
    means <- calc.new.means(x, clusters, k)
    difference <- delta(prev.means, means)
    iterations <- iterations + 1
  }
  return(list(iters=iterations, cluster=clusters, centers=means))
}

k <- 3
threshold <- 0.11

# ensure that the input matrix only has 2 columns
results <- my_kmeans(x[,1:2], k, threshold)

# create a results matrix with cluster info for filtering convinience
res_m <- cbind(x[,1:2], results$cluster) 

with_outliers <- c()
for (i in 1:k) {
  res_cluster <- res_m[res_m[,3] == i,]
  cov_matrix <- cov(res_cluster[,1:2])
  m_dist <- mahalanobis(res_cluster[, 1:2], colMeans(res_cluster[,1:2]), cov_matrix)
  res_cluster <- cbind(res_cluster, m_dist)
  with_outliers <- rbind(with_outliers, res_cluster)
}

# calculate covariance matrix

distances = c()
for (i in seq(along=results$cluster)){
  dst <- mahalanobis.dist(x[i,], results$centers[results$cluster[i]], cov_matrix)
  distances <- c(distances, dst)
}
two_st_dev = sd(distances) * 2
with_outliers = c()
for (i in seq(along=results$cluster)){
  if (distances[i] > two_st_dev) with_outliers <- c(with_outliers, k+1)
  else with_outliers <- c(with_outliers, results$cluster[i])
}
m_dist <- mahalanobis(x[, 1:2], colMeans(x[,1:2]), cov(x[,1:2]))

plot(x, col = m_dist)
points(results$centers, col = 1:k, pch = 8)


